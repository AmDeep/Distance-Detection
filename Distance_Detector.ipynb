{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython pyyaml==5.1\n",
    "\n",
    "# install detectron2:\n",
    "!pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read A Video and Frames\n",
    "%%time\n",
    "!rm -r frames/*\n",
    "!mkdir frames/\n",
    "\n",
    "#specify path to video\n",
    "video = \"sample.mp4\"\n",
    "\n",
    "#capture video\n",
    "cap = cv2.VideoCapture(video)\n",
    "cnt=0\n",
    "\n",
    "# Check if video file is opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "ret,first_frame = cap.read()\n",
    "\n",
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "     \n",
    "  if ret == True:\n",
    "\n",
    "    #save each frame to folder        \n",
    "    cv2.imwrite('frames/'+str(cnt)+'.png', frame)\n",
    "    cnt=cnt+1\n",
    "    if(cnt==750):\n",
    "      break\n",
    "\n",
    "  # Break the loop\n",
    "  else: \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame rate of a video\n",
    "FPS=cap.get(cv2.CAP_PROP_FPS)\n",
    "print(FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set threshold for this model\n",
    "\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read an image\n",
    "img = cv2.imread(\"frames/30.png\")\n",
    "\n",
    "#pass to the model\n",
    "outputs = predictor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=outputs['instances'].pred_classes.cpu().numpy()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "print(bbox)\n",
    "#identity only persons \n",
    "ind = np.where(classes==0)[0]\n",
    "\n",
    "#identify bounding box of only persons\n",
    "person=bbox[ind]\n",
    "\n",
    "#total no. of persons\n",
    "num= len(person)\n",
    "\n",
    "x1,y1,x2,y2 = person[0]\n",
    "print(x1,y1,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('frames/30.png')\n",
    "_ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute center \n",
    "x_center = int((x1+x2)/2)\n",
    "y_center = int(y2)\n",
    "\n",
    "center = (x_center, y_center)\n",
    "\n",
    "_ = cv2.circle(img, center, 5, (255, 0, 0), -1)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function which return the bottom center of every bbox\n",
    "def mid_point(img,person,idx):\n",
    "  #get the coordinates\n",
    "  x1,y1,x2,y2 = person[idx]\n",
    "  _ = cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
    "  \n",
    "  #compute bottom center of bbox\n",
    "  x_mid = int((x1+x2)/2)\n",
    "  y_mid = int(y2)\n",
    "  mid   = (x_mid,y_mid)\n",
    "  \n",
    "  _ = cv2.circle(img, mid, 5, (0, 0, 255), -1)\n",
    "  cv2.putText(img, str(idx), mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "  \n",
    "  return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the function\n",
    "midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
    "\n",
    "#visualize image\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from scipy.spatial import distance\n",
    "def compute_distance(midpoints,num):\n",
    "  dist = np.zeros((num,num))\n",
    "  for i in range(num):\n",
    "    for j in range(i+1,num):\n",
    "      if i!=j:\n",
    "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
    "        dist[i][j]=dst\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist= compute_distance(midpoints,num)\n",
    "%%time\n",
    "def find_closest(dist,num,thresh):\n",
    "  p1=[]\n",
    "  p2=[]\n",
    "  d=[]\n",
    "  for i in range(num):\n",
    "    for j in range(i,num):\n",
    "      if( (i!=j) & (dist[i][j]<=thresh)):\n",
    "        p1.append(i)\n",
    "        p2.append(j)\n",
    "        d.append(dist[i][j])\n",
    "  return p1,p2,d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "thresh=100\n",
    "p1,p2,d=find_closest(dist,num,thresh)\n",
    "df = pd.DataFrame({\"p1\":p1,\"p2\":p2,\"dist\":d})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_2_red(img,person,p1,p2):\n",
    "  risky = np.unique(p1+p2)\n",
    "  for i in risky:\n",
    "    x1,y1,x2,y2 = person[i]\n",
    "    _ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = change_2_red(img,person,p1,p2)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "names=os.listdir('frames/')\n",
    "names.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "def find_closest_people(name,thresh):\n",
    "\n",
    "  img = cv2.imread('frames/'+name)\n",
    "  outputs = predictor(img)\n",
    "  classes=outputs['instances'].pred_classes.cpu().numpy()\n",
    "  bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
    "  ind = np.where(classes==0)[0]\n",
    "  person=bbox[ind]\n",
    "  midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
    "  num = len(midpoints)\n",
    "  dist= compute_distance(midpoints,num)\n",
    "  p1,p2,d=find_closest(dist,num,thresh)\n",
    "  img = change_2_red(img,person,p1,p2)\n",
    "  cv2.imwrite('frames/'+name,img)\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "thresh=100\n",
    "_ = [find_closest_people(names[i],thresh) for i in tqdm(range(len(names))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "frames = os.listdir('frames/')\n",
    "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "\n",
    "frame_array=[]\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    \n",
    "    #reading each files\n",
    "    img = cv2.imread('frames/'+frames[i])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('sample_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    " \n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
